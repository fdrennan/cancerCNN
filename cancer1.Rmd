git p---
title: "R Notebook"
output:
  html_document:
    df_print: paged
editor_options: 
  chunk_output_type: console
---

Load all the packages we will need.

```{r setup, include=FALSE}
rm(list = ls())
knitr::opts_chunk$set(message = FALSE, warning = FALSE)
```

```{r}
library(tidyverse)
library(imager)
library(keras)
```


Variables
```{r}
test_dir = "test"
file_names = list.files(test_dir)
```


Visualize some of the images. 
```{r}
par(xaxt = "n", yaxt = "n", mar = c(1, 0, 1, 0), xaxs = "i", mfrow = c(3, 4))
rand_images = list()
for(i in 1:12) {
  random_image = sample(file_names, 1)
  random_image_path = file.path(test_dir, random_image)
  random_image_data = load.image(random_image_path)
  rand_images[[i]] = as.array(random_image_data)
  plot(random_image_data)
}
```



Check out the data we have

```{r}
# train_labels = read_csv('train_labels.csv')
```

```{r}
# for(i in seq_along(train_labels$id)) {
#   
#   if(train_labels$label[i] == 1) {
#     is_validation = sample(1:10, 1) > 7
#     if(is_validation) {
#       file.copy(paste0("train/", train_labels$id[i], ".tif"),
#               paste0("validation_images/cancer/", train_labels$id[i], ".tif"))
#     } else {
#       file.copy(paste0("train/", train_labels$id[i], ".tif"),
#               paste0("images/cancer/", train_labels$id[i], ".tif"))
#     }
#   } else {
#     is_validation = sample(1:10, 1) > 7
#     if(is_validation) { 
#     file.copy(paste0("train/", train_labels$id[i], ".tif"),
#               paste0("validation_images/not_cancer/", train_labels$id[i], ".tif"))
#     } else {
#       file.copy(paste0("train/", train_labels$id[i], ".tif"),
#               paste0("images/not_cancer/", train_labels$id[i], ".tif"))
#     }
#   }
#   print(is_validation)
#   print(i/200000)
# }
```

```{r}
train_datagen = image_data_generator(
  rescale = 1/255
  # rotation_range = 200,
  # width_shift_range = 0.2,
  # height_shift_range = 0.2,
  # shear_range = 0.2,
  # zoom_range = 0.2,
  # horizontal_flip = TRUE,
  # fill_mode = "nearest"
)
train_generator = flow_images_from_directory(
  "images",
  train_datagen,
  target_size = c(96, 96),
  batch_size = 20,
  class_mode = "binary"
)
```

```{r}
validation_datagen = image_data_generator(
  rescale = 1/255,
  rotation_range = 40,
  width_shift_range = 0.2,
  height_shift_range = 0.2,
  shear_range = 0.2,
  zoom_range = 0.2,
  horizontal_flip = TRUE,
  fill_mode = "nearest"
)
validation_generator = flow_images_from_directory(
  "validation_images",
  validation_datagen,
  target_size = c(96, 96),
  batch_size = 100,
  class_mode = "binary"
)
```

```{r}
model <- keras_model_sequential() %>% 
  layer_conv_2d(filters = 32, 
                kernel_size = c(3, 3), 
                activation = "relu",
                data_format ='channels_last',
                input_shape = c(96, 96, 3)) %>% 
  layer_max_pooling_2d(pool_size = c(2, 2)) %>% 
  layer_conv_2d(filters = 64, kernel_size = c(3, 3)) %>%
  layer_activation_relu() %>% 
  # layer_max_pooling_2d(pool_size = c(2, 2)) %>%
  # layer_conv_2d(filters = 128, kernel_size = c(3, 3)) %>%
  # layer_activation_relu() %>% 
  # layer_max_pooling_2d(pool_size = c(2, 2)) %>%
  # layer_conv_2d(filters = 128, kernel_size = c(3, 3)) %>%
  # layer_activation_relu() %>% 
  # layer_max_pooling_2d(pool_size = c(2, 2)) %>%
  # layer_activation_leaky_relu() %>% 
  # layer_max_pooling_2d(pool_size = c(2, 2)) %>%
  # layer_conv_2d(filters = 128, kernel_size = c(3, 3)) %>%
  # layer_activation_relu() %>% 
  layer_flatten() %>%
  # layer_dropout(.1) %>% 
  layer_dense(units = 512, activation = "relu") %>%
  layer_dense(units = 1, activation = "sigmoid")
```

```{r}
print(model)
```

```{r, echo=TRUE, results='hide'}

if(TRUE) {
   model %>% compile(
    optimizer = optimizer_rmsprop(lr = .01),
    loss = "binary_crossentropy",
    metrics = "accuracy"
  )
                
  model %>% fit_generator(
    train_generator,
    steps_per_epoch = 10,
    epochs = 100,
    validation_data = validation_generator,
    validation_steps = 5
  )
  
} else {
  
  parallel_model <- multi_gpu_model(model, gpus = 1)
    parallel_model %>% compile(
     optimizer = optimizer_rmsprop(lr = 1e-4),
    loss = "binary_crossentropy",
    metrics = "accuracy"
    )
  
  parallel_model %>% fit_generator(
    train_generator,
    steps_per_epoch = 1000,
    epochs = 30,
    validation_data = validation_generator,
    validation_steps = 20
  )
}


```

```{r}
```
